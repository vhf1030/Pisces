{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. í•„ìš” íŒŒì¼ ëª©ë¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  'nst_{fish}_trend_2025-01-17.csv'\n",
    "*  'forecast_agg.csv'\n",
    "* 'item_price_lag_filled.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ê²½ì œì§€í‘œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "filled_economic_indicators.csv ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. yfinanceì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ :  ì—†ìŒ\n",
    "* ì¶œë ¥ íŒŒì¼ : '_economic_indicators_.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "# ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ì„¤ì •\n",
    "start_date = '2015-01-01'\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ì €ì¥í•  ë¹ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# ê° ì§€í‘œì˜ í‹°ì»¤ ì‹¬ë³¼ ì •ì˜\n",
    "tickers = {\n",
    "    'KOSPI': '^KS11',  # KOSPI\n",
    "    'USD/KRW': 'KRW=X',  # ì›ë‹¬ëŸ¬ í™˜ìœ¨\n",
    "    'WTI': 'CL=F',  # WTI ì›ìœ  ì„ ë¬¼\n",
    "    'VIX': '^VIX',  # VIX ì§€ìˆ˜\n",
    "    'Gold': 'GC=F',  # ê¸ˆ ì„ ë¬¼\n",
    "    'Silver': 'SI=F',  # ì€ ì„ ë¬¼\n",
    "    'MOVE' : '^MOVE' # MOVE Index\n",
    "}\n",
    "\n",
    "# ê° í‹°ì»¤ì— ëŒ€í•´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "for name, ticker in tickers.items():\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date)\n",
    "        # ì¢…ê°€ë§Œ ì‚¬ìš©\n",
    "        df_final[name] = df['Close']\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {name}: {e}\")\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "df_final = df_final.fillna(method='ffill')\n",
    "\n",
    "# ë°ì´í„° í™•ì¸\n",
    "print(\"\\nFirst few rows of the data:\")\n",
    "print(df_final.head())\n",
    "\n",
    "# ê¸°ë³¸ í†µê³„ í™•ì¸\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df_final.describe())\n",
    "\n",
    "# CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "output_filename = '_economic_indicators_.csv'\n",
    "df_final.to_csv(output_filename)\n",
    "print(f\"\\nData saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. ê²½ì œì§€í‘œ ë°ì´í„° ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° \n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : '_economic_indicators_.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'filled_economic_indicators_.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv('_economic_indicators_.csv', encoding='utf-8')\n",
    "\n",
    "# Date ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# ì‹œì‘ì¼ê³¼ ë§ˆì§€ë§‰ì¼ ì¶”ì¶œ\n",
    "start_date = df['Date'].min()\n",
    "end_date = df['Date'].max()\n",
    "\n",
    "# ëª¨ë“  ë‚ ì§œê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "all_dates = pd.DataFrame(\n",
    "    {'Date': pd.date_range(start_date, end_date, freq='D')}\n",
    ")\n",
    "\n",
    "# ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©\n",
    "filled_df = pd.merge(all_dates, df, on='Date', how='left')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ë¥¼ ì´ì „ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "filled_df = filled_df.ffill()\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "filled_df.to_csv('filled_economic_indicators.csv', index=False)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"ì²˜ë¦¬ëœ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "print(filled_df.head())\n",
    "print(\"\\nê²°ì¸¡ì¹˜ í™•ì¸:\")\n",
    "print(filled_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. íŠ¸ë Œë“œ ë°ì´í„° ì–´ì¢…ë³„ë¡œ ê·¸ë£¹í™”\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. ê·¸ë£¹í™” í•¨ìˆ˜ ìƒì„± ë° ì €ì¥\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'nst_{fish}_trend_2025-01-17.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'ê·¸ë£¹í™”_nst_{fish}_trend_2025-01-17.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_age_groups(file_path):\n",
    "    # CSV íŒŒì¼ ì½ê¸°\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    \n",
    "    # ì—°ë ¹ëŒ€ ê·¸ë£¹ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "    age_mapping = {\n",
    "        '19_24': '20ëŒ€',\n",
    "        '25_29': '20ëŒ€',\n",
    "        '30_34': '30ëŒ€',\n",
    "        '35_39': '30ëŒ€',\n",
    "        '40_44': '40ëŒ€',\n",
    "        '45_49': '40ëŒ€',\n",
    "        '50_54': '50ëŒ€',\n",
    "        '55_59': '50ëŒ€',\n",
    "        '60_80': '60ëŒ€ ì´ìƒ'\n",
    "    }\n",
    "    \n",
    "    # ì›í•˜ëŠ” ì—°ë ¹ëŒ€ë§Œ í•„í„°ë§\n",
    "    df = df[df['age'].isin(age_mapping.keys())]\n",
    "    \n",
    "    # ìƒˆë¡œìš´ ì—°ë ¹ëŒ€ ì»¬ëŸ¼ ìƒì„±\n",
    "    df['age_group'] = df['age'].map(age_mapping)\n",
    "    \n",
    "    # ì¼ìë³„, ìƒˆë¡œìš´ ì—°ë ¹ëŒ€ë³„ë¡œ score í•©ì‚°\n",
    "    result = df.groupby(['date', 'name', 'age_group'])['score'].sum().reset_index()\n",
    "    \n",
    "    # í”¼ë²— í…Œì´ë¸”ë¡œ ë³€í™˜í•˜ì—¬ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬\n",
    "    pivot_result = result.pivot(index=['date', 'name'], \n",
    "                              columns='age_group', \n",
    "                              values='score').reset_index()\n",
    "    \n",
    "    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬\n",
    "    column_order = [ 'date', 'name', '20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ëŒ€ ì´ìƒ']\n",
    "    pivot_result = pivot_result[column_order]\n",
    "    \n",
    "    return pivot_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ìˆ˜ì‚°ë¬¼ ì¢…ë¥˜ë³„ íŒŒì¼ ê²½ë¡œ ë° ì´ë¦„ ì„¤ì •\n",
    "fish_files = {\n",
    "    'ê´‘ì–´': '../../data/raw/nst_ê´‘ì–´_trend_2025-01-17.csv',\n",
    "    'ë†ì–´': '../../data/raw/nst_ë†ì–´_trend_2025-01-17.csv',\n",
    "    'ëŒ€ê²Œ': '../../data/raw/nst_ëŒ€ê²Œ_trend_2025-01-17.csv',\n",
    "    'ë°©ì–´': '../../data/raw/nst_ë°©ì–´_trend_2025-01-17.csv',\n",
    "    'ì—°ì–´': '../../data/raw/nst_ì—°ì–´_trend_2025-01-17.csv',\n",
    "    'ìš°ëŸ­': '../../data/raw/nst_ìš°ëŸ­_trend_2025-01-17.csv',\n",
    "    'ì°¸ë”': '../../data/raw/nst_ì°¸ë”_trend_2025-01-17.csv'\n",
    "}\n",
    "\n",
    "#  ê°œë³„ íŒŒì¼ ì €ì¥ + ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥ ì¤€ë¹„\n",
    "all_results = {}\n",
    "\n",
    "#  ëª¨ë“  íŒŒì¼ ì²˜ë¦¬\n",
    "for fish, file_path in fish_files.items():\n",
    "    try:\n",
    "        processed_df = process_age_groups(file_path, fish)\n",
    "\n",
    "        # ê°œë³„ íŒŒì¼ ì €ì¥\n",
    "        output_filename = f'ê·¸ë£¹í™”_nst_{fish}_trend_2025-01-17.csv'\n",
    "        processed_df.to_csv(output_filename, index=False)\n",
    "\n",
    "        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì²« 3ê°œ í–‰ë§Œ ì €ì¥)\n",
    "        all_results[fish] = processed_df.head(3)\n",
    "\n",
    "        print(f\"âœ… '{output_filename}' ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {fish}: {e}\")\n",
    "\n",
    "#  ìµœì¢… ì²˜ë¦¬ëœ ê²°ê³¼ ì¶œë ¥ (ê°ê° 3ê°œ í–‰ë§Œ ì¶œë ¥)\n",
    "print(\"\\nğŸ“Š ìµœì¢… ì²˜ë¦¬ëœ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ê°ê° ìƒìœ„ 3ê°œ í–‰)\\n\")\n",
    "for fish, df_sample in all_results.items():\n",
    "    print(f\"{fish} ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "    print(df_sample)\n",
    "    print(\"-\" * 50)  # êµ¬ë¶„ì„  ì¶”ê°€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. merged_trends.csv ì €ì¥\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'ê·¸ë£¹í™”_nst_{fish}_trend_2025-01-17.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'merged_trends.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fish_trends(file_paths, output_path):\n",
    "   # ì²« ë²ˆì§¸ íŒŒì¼ ë¡œë“œ ë° name ì»¬ëŸ¼ ì œê±°\n",
    "   merged_df = pd.read_csv(file_paths[0], encoding='utf-8')\n",
    "   merged_df = merged_df.drop('name', axis=1)\n",
    "   merged_df['date'] = pd.to_datetime(merged_df['date'])\n",
    "   \n",
    "   # ë‚˜ë¨¸ì§€ íŒŒì¼ë“¤ ë³‘í•©\n",
    "   for file_path in file_paths[1:]:\n",
    "       df = pd.read_csv(file_path, encoding='utf-8')\n",
    "       df = df.drop('name', axis=1)\n",
    "       df['date'] = pd.to_datetime(df['date'])\n",
    "       merged_df = pd.merge(merged_df, df, on='date', how='outer')\n",
    "   \n",
    "   # ë‚ ì§œìˆœ ì •ë ¬\n",
    "   result = merged_df.sort_values('date')\n",
    "   \n",
    "   # CSV ì €ì¥\n",
    "   result.to_csv(output_path, index=False, encoding='utf-8')\n",
    "   return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš© ì˜ˆì‹œ:\n",
    "files = [\n",
    "    'ê·¸ë£¹í™”_nst_ê´‘ì–´_trend_2025-01-17.csv', \n",
    "    'ê·¸ë£¹í™”_nst_ë†ì–´_trend_2025-01-17.csv', \n",
    "    'ê·¸ë£¹í™”_nst_ëŒ€ê²Œ_trend_2025-01-17.csv', \n",
    "    'ê·¸ë£¹í™”_nst_ë°©ì–´_trend_2025-01-17.csv', \n",
    "    'ê·¸ë£¹í™”_nst_ì—°ì–´_trend_2025-01-17.csv', \n",
    "    'ê·¸ë£¹í™”_nst_ìš°ëŸ­_trend_2025-01-17.csv', \n",
    "    'ê·¸ë£¹í™”_nst_ì°¸ë”_trend_2025-01-17.csv'\n",
    "    ]\n",
    "\n",
    "result = merge_fish_trends(files, 'merged_trends.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ê¸°ìƒ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'forecast_agg.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'weatherdata_processed.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•¨ìˆ˜ ì •ì˜\n",
    "\n",
    "def create_weather_columns(df, station_cols, output_path):\n",
    "   result_df = df.copy()\n",
    "   result_df['ì¼ì‹œ'] = pd.to_datetime(result_df['ì¼ì‹œ'])\n",
    "   \n",
    "   final_df = pd.DataFrame({'ì¼ì‹œ': result_df['ì¼ì‹œ'].unique()})\n",
    "   \n",
    "   for station, columns in station_cols.items():\n",
    "       station_data = result_df[result_df['ì§€ì '] == station].copy()\n",
    "       \n",
    "       for orig_col, new_col in columns:\n",
    "           station_col = station_data[['ì¼ì‹œ', orig_col]].copy()\n",
    "           final_df = pd.merge(final_df, station_col.rename(columns={orig_col: new_col}), \n",
    "                             on='ì¼ì‹œ', how='left')\n",
    "   \n",
    "   # ì¹¼ëŸ¼ì„ ê°€ë‚˜ë‹¤ìˆœìœ¼ë¡œ ì •ë ¬ ('ì¼ì‹œ' ì»¬ëŸ¼ì€ ì²«ë²ˆì§¸ë¡œ ìœ ì§€)\n",
    "   sorted_cols = ['ì¼ì‹œ'] + sorted([col for col in final_df.columns if col != 'ì¼ì‹œ'])\n",
    "   result = final_df[sorted_cols].sort_values('ì¼ì‹œ')\n",
    "   \n",
    "   result.to_csv(output_path, index=False, encoding='utf-8')\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV íŒŒì¼ ì½ê¸°\n",
    "df = pd.read_csv('forecast_agg.csv', encoding='utf-8')\n",
    "\n",
    "# í”¼ì³ ì„ íƒ\n",
    "station_columns = {\n",
    "\t22105: [\n",
    "\t\t('ê¸°ì˜¨', 'ê´‘ì–´_ê¸°ì˜¨_22105'),\n",
    "\t\t('ê¸°ì˜¨', 'ë†ì–´_ê¸°ì˜¨_22105'),\n",
    "\t\t('ê¸°ì˜¨', 'ëŒ€ê²Œ_ê¸°ì˜¨_22105'),\n",
    "\t\t('íŒŒì£¼ê¸°', 'ëŒ€ê²Œ_íŒŒì£¼ê¸°_22105'),\n",
    "\t\t('íŒŒì£¼ê¸°', 'ë°©ì–´_íŒŒì£¼ê¸°_22105'),\n",
    "\t\t('ê¸°ì˜¨', 'ì—°ì–´_ê¸°ì˜¨_22105'),\n",
    "\t\t('ìŠµë„', 'ì—°ì–´_ìŠµë„_22105')\n",
    "\t],\n",
    "    \n",
    "\t22107: [\n",
    "\t\t('ìˆ˜ì˜¨', 'ê´‘ì–´_ìˆ˜ì˜¨_22107'),\n",
    "\t\t('ìˆ˜ì˜¨', 'ë†ì–´_ìˆ˜ì˜¨_22107'),\n",
    "\t\t('ìˆ˜ì˜¨', 'ë°©ì–´_ìˆ˜ì˜¨_22107'),\n",
    "\t\t('ìˆ˜ì˜¨', 'ì—°ì–´_ìˆ˜ì˜¨_22107'),\n",
    "\t\t('ìˆ˜ì˜¨', 'ì°¸ë”_ìˆ˜ì˜¨_22107')\n",
    "\t],\n",
    "\n",
    "\t22186: [\n",
    "\t\t('ìŠµë„', 'ê´‘ì–´_ìŠµë„_22186'),\n",
    "\t\t('ìŠµë„', 'ë†ì–´_ìŠµë„_22186'),\n",
    "\t\t('ê¸°ì˜¨', 'ìš°ëŸ­_ê¸°ì˜¨_22186'),\n",
    "\t\t('ìˆ˜ì˜¨', 'ìš°ëŸ­_ìˆ˜ì˜¨_22186')\n",
    "\t\t],\n",
    "        \n",
    "\t22188: [\n",
    "\t\t('ìˆ˜ì˜¨', 'ëŒ€ê²Œ_ìˆ˜ì˜¨_22188'),\n",
    "\t\t('ìŠµë„', 'ëŒ€ê²Œ_ìŠµë„_22188')\n",
    "\t\t],        \n",
    "\n",
    "\t22189: [\n",
    "\t\t('íŒŒì£¼ê¸°', 'ìš°ëŸ­_íŒŒì£¼ê¸°_22189')\n",
    "\t\t],       \n",
    "\n",
    "\t22190: [\n",
    "\t\t('íŒŒì£¼ê¸°', 'ê´‘ì–´_íŒŒì£¼ê¸°_22190'),\n",
    "        ('íŒŒì£¼ê¸°', 'ë†ì–´_íŒŒì£¼ê¸°_22190'),\n",
    "        ('ê¸°ì˜¨', 'ë°©ì–´_ê¸°ì˜¨_22190'),\n",
    "        ('ìŠµë„', 'ë°©ì–´_ìŠµë„_22190'),\n",
    "        ('íŒŒì£¼ê¸°', 'ì—°ì–´_íŒŒì£¼ê¸°_22190'),\n",
    "        ('ìŠµë„', 'ìš°ëŸ­_ìŠµë„_22190'),\n",
    "        ('ê¸°ì˜¨', 'ì°¸ë”_ê¸°ì˜¨_22190'),\n",
    "        ('ìŠµë„', 'ì°¸ë”_ìŠµë„_22190'),\n",
    "        ('íŒŒì£¼ê¸°', 'ì°¸ë”_íŒŒì£¼ê¸°_22190')\n",
    "\t\t]  \n",
    "\n",
    "\t}\n",
    "\n",
    "result = create_weather_columns(df, station_columns, 'weatherdata_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ë³€ìˆ˜ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'filled_economic_indicators_.csv',  'merged_trends.csv', 'weatherdata_processed.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'merged_all_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_data(output_path='merged_all_data.csv'):\n",
    "   # ê° íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "   \n",
    "   economic = pd.read_csv('_filled_economic_indicators.csv', encoding='utf-8')\n",
    "   economic['Date'] = pd.to_datetime(economic['Date'])\n",
    "   economic = economic.rename(columns={'Date': 'ë‚ ì§œ'})\n",
    "   \n",
    "   trends = pd.read_csv('merged_trends.csv', encoding='utf-8')\n",
    "   trends['date'] = pd.to_datetime(trends['date'])\n",
    "   trends = trends.rename(columns={'date': 'ë‚ ì§œ'})\n",
    "   \n",
    "   weather = pd.read_csv('weatherdata_processed.csv', encoding='utf-8')\n",
    "   weather['date'] = pd.to_datetime(weather['date'])\n",
    "   weather = weather.rename(columns={'date': 'ë‚ ì§œ'})\n",
    "   \n",
    "   # ëª¨ë“  ë‚ ì§œ ì¶”ì¶œ\n",
    "   all_dates = pd.concat([\n",
    "        economic['ë‚ ì§œ'], \n",
    "        trends['ë‚ ì§œ'], \n",
    "       weather['ë‚ ì§œ']\n",
    "   ]).unique()\n",
    "   \n",
    "   # ë‚ ì§œ ê¸°ì¤€ ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "   date_df = pd.DataFrame({'ë‚ ì§œ': all_dates})\n",
    "   date_df = date_df.sort_values('ë‚ ì§œ')\n",
    "   \n",
    "   # ë°ì´í„° ë³‘í•©\n",
    "   dfs = [\n",
    "\t\tdate_df, \n",
    "\t\teconomic, \n",
    "\t\ttrends,\n",
    "\t\tweather\n",
    "   ]\n",
    "   \n",
    "   result = dfs[0]\n",
    "   for df in dfs[1:]:\n",
    "       result = pd.merge(result, df, on='ë‚ ì§œ', how='left')\n",
    "   \n",
    "   # ê²°ê³¼ ì €ì¥\n",
    "   result.to_csv(output_path, index=False, encoding='utf-8')\n",
    "   return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = merge_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'merged_all_data.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'filled_merged_all_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(file_path, output_path):\n",
    "    \"\"\"\n",
    "    CSV íŒŒì¼ì—ì„œ ê²°ì¸¡ì¹˜ë¥¼ `ffill`ì„ ì‚¬ìš©í•˜ì—¬ ì±„ìš°ë˜, ì´ì „ ê°’ì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ .\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ.\n",
    "        output_path (str): ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì €ì¥í•  ê²½ë¡œ.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: ê²°ì¸¡ì¹˜ê°€ ì±„ì›Œì§„ ë°ì´í„°í”„ë ˆì„.\n",
    "    \"\"\"\n",
    "    \n",
    "    # CSV íŒŒì¼ ë¡œë“œ\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ í™•ì¸ (ì²˜ë¦¬ ì „)\n",
    "    missing_before = df.isnull().sum()\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ `ffill`ë¡œ ì±„ìš°ê¸° (ì´ì „ ê°’ì´ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ )\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ í™•ì¸ (ì²˜ë¦¬ í›„)\n",
    "    missing_after = df.isnull().sum()\n",
    "\n",
    "    # ë³€ê²½ëœ ê²°ì¸¡ì¹˜ ê°œìˆ˜ ì¶œë ¥\n",
    "    missing_summary = pd.DataFrame({'Before': missing_before, 'After': missing_after})\n",
    "    print(\"\\nğŸ” ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì „í›„ ë¹„êµ:\")\n",
    "    print(missing_summary)\n",
    "\n",
    "    # ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nâœ… ì²˜ë¦¬ëœ ë°ì´í„°ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'merged_all_data.csv'\n",
    "output_path = 'filled_merged_all_data.csv'\n",
    "\n",
    "fill_missing_values(file_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. íƒ€ì„ë˜ê·¸ ì ìš©í•˜ê¸° \n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'filled_merged_all_data.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'timelagged_features.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1. ì„¤ì •ëœ íƒ€ì„ë˜ê·¸ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv('filled_merged_all_data.csv', encoding='utf-8')\n",
    "df['date'] = pd.to_datetime(df['ë‚ ì§œ'])\n",
    "\n",
    "# ê° ì¹¼ëŸ¼ë³„ lag ì¼ìˆ˜ ì •ì˜\n",
    "lag_days = {\n",
    "\n",
    "'ì—°ì–´_ê±°ë˜ëŸ‰(í†¤)' : 374,\n",
    "'ì—°ì–´_ê°€ê²©(NOK/kg)' : 32,\n",
    "\n",
    "'ê´‘ì–´_ëŒ€'  : 64,\n",
    "'ë°©ì–´(ìì—°)_ëŒ€_ê°€ë½' : 5,\n",
    "'ì°¸ë”_ëŒ€_ê°€ë½' : 1,\n",
    "\n",
    "'ê´‘ì–´_KOSPI' : 136,\n",
    "'ê´‘ì–´_USD/KRW' : 1,\n",
    "'ê´‘ì–´_WTI' : 1,\n",
    "'ê´‘ì–´_VIX' : 399,\n",
    "'ê´‘ì–´_Gold' : 314,\n",
    "'ê´‘ì–´_Silver' : 238,\n",
    "'ê´‘ì–´_MOVE' : 18,\n",
    "\n",
    "'ë†ì–´_KOSPI' : 179,\n",
    "'ë†ì–´_USD/KRW' : 1,\n",
    "'ë†ì–´_WTI' : 100,\n",
    "'ë†ì–´_VIX' : 391,\n",
    "'ë†ì–´_Gold' : 361,\n",
    "'ë†ì–´_Silver' : 290,\n",
    "'ë†ì–´_MOVE' : 1,\n",
    "\n",
    "'ëŒ€ê²Œ_KOSPI' : 148,\n",
    "'ëŒ€ê²Œ_USD/KRW' : 90,\n",
    "'ëŒ€ê²Œ_WTI' : 91,\n",
    "# 'ëŒ€ê²Œ_VIX' : \n",
    "'ëŒ€ê²Œ_Gold' : 177,\n",
    "'ëŒ€ê²Œ_Silver' : 177,\n",
    "# 'ëŒ€ê²Œ_MOVE' : \n",
    "\n",
    "'ë°©ì–´_KOSPI' : 282,\n",
    "'ë°©ì–´_USD/KRW' : 387,\n",
    "'ë°©ì–´_WTI' : 399,\n",
    "'ë°©ì–´_VIX' : 133,\n",
    "'ë°©ì–´_Gold' : 1,\n",
    "'ë°©ì–´_Silver' : 1,\n",
    "'ë°©ì–´_MOVE' : 381,\n",
    "\n",
    "'ì—°ì–´_KOSPI' : 329,\n",
    "'ì—°ì–´_USD/KRW' : 1,\n",
    "'ì—°ì–´_WTI' : 199,\n",
    "'ì—°ì–´_VIX' : 399,\n",
    "'ì—°ì–´_Gold' : 1,\n",
    "'ì—°ì–´_Silver' : 399,\n",
    "'ì—°ì–´_MOVE' : 71,\n",
    "\n",
    "'ìš°ëŸ­_KOSPI' : 155,\n",
    "'ìš°ëŸ­_USD/KRW' : 121,\n",
    "'ìš°ëŸ­_WTI' : 14,\n",
    "'ìš°ëŸ­_VIX' : 38,\n",
    "'ìš°ëŸ­_Gold' : 146,\n",
    "'ìš°ëŸ­_Silver' : 125,\n",
    "# 'ìš°ëŸ­_MOVE' : \n",
    "\n",
    "'ì°¸ë”_KOSPI' : 399,\n",
    "'ì°¸ë”_USD/KRW' : 11,\n",
    "'ì°¸ë”_WTI' : 150,\n",
    "# 'ì°¸ë”_VIX' : \n",
    "# 'ì°¸ë”_Gold' : \n",
    "# 'ì°¸ë”_Silver' : \n",
    "'ì°¸ë”_MOVE' : 201,\n",
    " \n",
    "'ê´‘ì–´_20ëŒ€' : 250,\n",
    "'ê´‘ì–´_30ëŒ€' : 317,\n",
    "'ê´‘ì–´_40ëŒ€' : 330,\n",
    "'ê´‘ì–´_50ëŒ€' : 395,\n",
    "'ê´‘ì–´_60ëŒ€ì´ìƒ' : 339,\n",
    "\n",
    "'ë†ì–´_20ëŒ€' : 305,\n",
    "'ë†ì–´_30ëŒ€' : 307,\n",
    "'ë†ì–´_40ëŒ€' : 309,\n",
    "'ë†ì–´_50ëŒ€' : 309,\n",
    "'ë†ì–´_60ëŒ€ì´ìƒ' : 273,\n",
    "\n",
    "'ëŒ€ê²Œ_20ëŒ€' : 273,\n",
    "'ëŒ€ê²Œ_30ëŒ€' : 370,\n",
    "'ëŒ€ê²Œ_40ëŒ€' : 5,\n",
    "'ëŒ€ê²Œ_50ëŒ€' : 5,\n",
    "'ëŒ€ê²Œ_60ëŒ€ì´ìƒ' : 5,\n",
    "\n",
    "'ë°©ì–´_20ëŒ€' : 22,\n",
    "'ë°©ì–´_30ëŒ€' : 26,\n",
    "'ë°©ì–´_40ëŒ€' : 256,\n",
    "'ë°©ì–´_50ëŒ€' : 256,\n",
    "'ë°©ì–´_60ëŒ€ì´ìƒ' : 26,\n",
    "\n",
    "'ì—°ì–´_20ëŒ€' : 20,\n",
    "'ì—°ì–´_30ëŒ€' : 15,\n",
    "'ì—°ì–´_40ëŒ€' : 21,\n",
    "'ì—°ì–´_50ëŒ€' : 15,\n",
    "'ì—°ì–´_60ëŒ€ì´ìƒ' : 397,\n",
    "\n",
    "'ìš°ëŸ­_20ëŒ€' : 22,\n",
    "'ìš°ëŸ­_30ëŒ€' : 354,\n",
    "'ìš°ëŸ­_40ëŒ€' : 354,\n",
    "'ìš°ëŸ­_50ëŒ€' : 220,\n",
    "'ìš°ëŸ­_60ëŒ€ì´ìƒ' : 219,\n",
    "\n",
    "'ì°¸ë”_20ëŒ€' : 197,\n",
    "'ì°¸ë”_30ëŒ€' : 167,\n",
    "'ì°¸ë”_40ëŒ€' : 278,\n",
    "'ì°¸ë”_50ëŒ€' : 193,\n",
    "'ì°¸ë”_60ëŒ€ì´ìƒ' : 14,\n",
    "\n",
    "\n",
    "'ê´‘ì–´_ê¸°ì˜¨_22105' : 97,\n",
    "'ê´‘ì–´_ìˆ˜ì˜¨_22107' : 79,\n",
    "'ê´‘ì–´_ìŠµë„_22186' : 349,\n",
    "'ê´‘ì–´_íŒŒì£¼ê¸°_22190' : 103,\n",
    "\n",
    "'ë†ì–´_ê¸°ì˜¨_22105' : 103,\n",
    "'ë†ì–´_ìˆ˜ì˜¨_22107' : 81,\n",
    "'ë†ì–´_ìŠµë„_22186' : 333,\n",
    "'ë†ì–´_íŒŒì£¼ê¸°_22190' : 115,\n",
    "\n",
    "'ëŒ€ê²Œ_ê¸°ì˜¨_22105' : 150,\n",
    "'ëŒ€ê²Œ_ìˆ˜ì˜¨_22188' : 140,\n",
    "'ëŒ€ê²Œ_ìŠµë„_22188' : 355,\n",
    "'ëŒ€ê²Œ_íŒŒì£¼ê¸°_22105' : 174,\n",
    "\n",
    "'ë°©ì–´_ê¸°ì˜¨_22190' : 114,\n",
    "'ë°©ì–´_ìˆ˜ì˜¨_22107' : 118,\n",
    "'ë°©ì–´_ìŠµë„_22190' : 158,\n",
    "'ë°©ì–´_íŒŒì£¼ê¸°_22105' : 191,\n",
    "\n",
    "'ì—°ì–´_ê¸°ì˜¨_22105' : 394,\n",
    "'ì—°ì–´_ìˆ˜ì˜¨_22107' : 341,\n",
    "'ì—°ì–´_ìŠµë„_22105' : 8,\n",
    "'ì—°ì–´_íŒŒì£¼ê¸°_22190' : 9,\n",
    "\n",
    "'ìš°ëŸ­_ê¸°ì˜¨_22186' : 118,\n",
    "'ìš°ëŸ­_ìˆ˜ì˜¨_22186' : 113,\n",
    "'ìš°ëŸ­_ìŠµë„_22190' : 159,\n",
    "'ìš°ëŸ­_íŒŒì£¼ê¸°_22189' : 172,\n",
    "\n",
    "'ì°¸ë”_ê¸°ì˜¨_22190' : 91,\n",
    "'ì°¸ë”_ìˆ˜ì˜¨_22107' : 72,\n",
    "'ì°¸ë”_ìŠµë„_22190' : 115,\n",
    "'ì°¸ë”_íŒŒì£¼ê¸°_22190' : 107\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# ê° ì¹¼ëŸ¼ì— ëŒ€í•´ ì§€ì •ëœ lag ì ìš©\n",
    "for col, lag in lag_days.items():\n",
    "   if col in df.columns:\n",
    "       df[f'{col}_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "df.to_csv('timelagged_features.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2 íŠ¸ë Œë“œ ë°ì´í„° lag 1 í•©ì¹˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ê°€ê²© ë°ì´í„° - ë…¸ëŸ‰ì§„ 2ì¸µ ë²„ë¦¬ê¸°\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'item_price_lag_filled.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'item_price_lag_filled_deleted.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "file_path = \"item_price_lag_filled.csv\"  # ì›ë³¸ ë°ì´í„° íŒŒì¼\n",
    "output_file = \"item_price_lag_filled_deleted.csv\"  # ì €ì¥ë  íŒŒì¼\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 'market' ì¹¼ëŸ¼ì—ì„œ 'ë…¸ëŸ‰ì§„ 2ì¸µ'ì¸ í–‰ ì œê±°\n",
    "df = df[df['market'] != 'ë…¸ëŸ‰ì§„ 2ì¸µ']\n",
    "\n",
    "# 'ë…¸ëŸ‰ì§„ 1ì¸µ'ì„ 'ë…¸ëŸ‰ì§„ì‹œì¥'ìœ¼ë¡œ ë³€ê²½\n",
    "df['market'] = df['market'].replace('ë…¸ëŸ‰ì§„ 1ì¸µ', 'ë…¸ëŸ‰ì§„ì‹œì¥')\n",
    "\n",
    "# ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# ë³€ê²½ëœ ë°ì´í„° í™•ì¸\n",
    "print(\"\\nâœ… ë³€ê²½ëœ ë°ì´í„° (ìƒìœ„ 5ê°œ í–‰):\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nğŸ“ ì²˜ë¦¬ëœ íŒŒì¼ì´ '{output_file}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. ì‹œì¥ ë°ì´í„° ì›í•« ì¸ì½”ë”©\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'item_price_lag_filled_deleted.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : 'item_price_oneHot.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import DateTime\n",
    "\n",
    "def transform_market_data(file_path):\n",
    "    # ë°ì´í„° ì½ê¸°\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # ì‹œì¥ë³„ ë”ë¯¸ë³€ìˆ˜ ìƒì„± (0, 1ë¡œ ì¸ì½”ë”©)\n",
    "    market_dummies = pd.get_dummies(df['market'], prefix='m').astype(int)\n",
    "    \n",
    "    # ì›ë³¸ ë°ì´í„°ì™€ ë”ë¯¸ë³€ìˆ˜ ê²°í•©\n",
    "    result = pd.concat([\n",
    "        df[['priceDate', 'item']], \n",
    "        market_dummies,\n",
    "        df[['avgPrice', 'avgPrice_lag_1']]\n",
    "    ], axis=1)\n",
    "    \n",
    "    # ë‚ ì§œì™€ ì–´ì¢…ìœ¼ë¡œ ì •ë ¬\n",
    "    result = result.sort_values(['priceDate', 'item'])\n",
    "    \n",
    "    # ë³€í™˜ëœ ë°ì´í„° ì €ì¥\n",
    "    output_file = 'item_price_oneHot.csv'\n",
    "    result.to_csv(output_file, index=False)\n",
    "    print(f\"ìƒì„±ëœ íŒŒì¼: {output_file}\")\n",
    "    print(\"\\nì²˜ìŒ 10ê°œ ì»¬ëŸ¼:\", result.columns[:10].tolist())\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ íŒŒì¼: transformed_market_data.csv\n",
      "\n",
      "ì²˜ìŒ 10ê°œ ì»¬ëŸ¼: ['priceDate', 'item', 'm_ê°€ë½ì‹œì¥', 'm_ê°•ì„œë†ìˆ˜ì‚°ë¬¼ì‹œì¥', 'm_êµ¬ë¦¬ë†ìˆ˜ì‚°ë¬¼ì‹œì¥', 'm_ë…¸ëŸ‰ì§„ 1ì¸µ', 'm_ë…¸ëŸ‰ì§„ 2ì¸µ', 'm_ë§ˆí¬ë†ìˆ˜ì‚°ë¬¼ì‹œì¥', 'm_ë¶€ì‚°ë¯¼ë½ì–´ë¯¼í™œì–´ì§íŒì¥', 'm_ì†Œë˜í¬êµ¬ì¢…í•©ì–´ì‹œì¥']\n"
     ]
    }
   ],
   "source": [
    "# Execute\n",
    "df = transform_market_data('item_price_lag_filled_deleted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. ê°€ê²©ë°ì´í„° ì–´ì¢…ë³„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : 'item_price_oneHot.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : '{fish}_price_oneHot.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_market_data():\n",
    "    df = pd.read_csv('item_price_oneHot.csv')\n",
    "    \n",
    "    for fish in df['item'].unique():\n",
    "        fish_df = df[df['item'] == fish]\n",
    "        output_file = f'{fish}_price_oneHot.csv'\n",
    "      # fish_df = fish_df.drop('item', axis=1)\n",
    "        fish_df.to_csv(output_file, index=False)\n",
    "        print(f'{fish} ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(fish_df)}ê°œ í–‰')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€ê²Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: 27677ê°œ í–‰\n",
      "ê´‘ì–´ ë°ì´í„° ìƒì„± ì™„ë£Œ: 31515ê°œ í–‰\n",
      "ë†ì–´ ë°ì´í„° ìƒì„± ì™„ë£Œ: 30651ê°œ í–‰\n",
      "ì—°ì–´ ë°ì´í„° ìƒì„± ì™„ë£Œ: 29588ê°œ í–‰\n",
      "ì°¸ë” ë°ì´í„° ìƒì„± ì™„ë£Œ: 27149ê°œ í–‰\n",
      "ë°©ì–´ ë°ì´í„° ìƒì„± ì™„ë£Œ: 11205ê°œ í–‰\n",
      "ìš°ëŸ­ ë°ì´í„° ìƒì„± ì™„ë£Œ: 6081ê°œ í–‰\n"
     ]
    }
   ],
   "source": [
    "split_market_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. ìµœì¢… ë°ì´í„° í•©ì¹˜ê¸°\n",
    "\n",
    "* ì…ë ¥ íŒŒì¼ : '{fish}_price_oneHot.csv', '{fish}_timelagged_features.csv'\n",
    "* ì¶œë ¥ íŒŒì¼ : '{fish}_price_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒì„±ëœ íŒŒì¼: ì°¸ë”_price_features.csv\n",
      "ì „ì²´ ì»¬ëŸ¼ ìˆ˜: 35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_features_price():\n",
    "    # ë‘ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "    features_df = pd.read_csv('../../data/features/ì°¸ë”_timelagged_features.csv')\n",
    "    price_df = pd.read_csv('../../data/features/oneHot/ì°¸ë”_price_oneHot.csv')\n",
    "    \n",
    "    # ë‚ ì§œ ì»¬ëŸ¼ëª… í†µì¼\n",
    "    price_df = price_df.rename(columns={'dmdpriceDate': 'date'})\n",
    "    \n",
    "    # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë³‘í•©\n",
    "    merged_df = pd.merge(price_df, features_df, on='date', how='left')\n",
    "    \n",
    "    # CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "    output_file = 'ì°¸ë”_price_features.csv'\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f'ìƒì„±ëœ íŒŒì¼: {output_file}')\n",
    "    print(f'ì „ì²´ ì»¬ëŸ¼ ìˆ˜: {len(merged_df.columns)}')\n",
    "\n",
    "merge_features_price()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311_cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
